{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_file = 'conn_bkm'\n",
    "connections = pd.read_csv(name_file+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def text_cleaning(x, cachedStopWords=cachedStopWords):\n",
    "    \"\"\"Clean text: remove non alphabetical words, stopwords and duplicate words\"\"\"\n",
    "    x = re.sub(r'[-\\\\/()]', ' ', x)\n",
    "    x = re.sub(r'[^a-zA-Z ]', '', x)\n",
    "    x = x.lower()\n",
    "    word_list =[]\n",
    "    \n",
    "    # make copy of stopwords\n",
    "    words = list(cachedStopWords)\n",
    "    for word in x.encode('utf-8').split():\n",
    "        if word not in words:\n",
    "            if word[-1]=='s':\n",
    "                word = word[:-1]\n",
    "                word = word.decode('utf-8')\n",
    "                #word = word[1:]\n",
    "                word_list.append(word)\n",
    "                words += [word]\n",
    "            else:\n",
    "                word = word.decode('utf-8')\n",
    "                #word = word[1:]\n",
    "                word_list.append(word)\n",
    "                words += [word]\n",
    "    \n",
    "    return ' '.join(word_list)\n",
    "\n",
    "\n",
    "##clean the test\n",
    "connections['Company'] = connections['Company'].map(str).map(lambda x: text_cleaning(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class jobListing():\n",
    "    def __init__(self, country_url = 'http://www.monsterindia.com/'):\n",
    "        self.url = country_url\n",
    "        self.headers = {'User-Agent':  \"\"\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36\"\"\"}\n",
    "        self.detail = defaultdict(list)\n",
    "        \n",
    "    def get_soups(self, q = '', loc = '', page=1):\n",
    "        \"\"\"Get html of jobs page\n",
    "        Params\n",
    "        -------\n",
    "        q: search query can be company number or title or any word in description\n",
    "        loc: location\"\"\"\n",
    "        q = re.sub( '\\s+', ' ', q ).strip()\n",
    "        q = re.sub( ' ', '-', q )\n",
    "        \n",
    "        self.params_list = q + '-jobs-in-'+ loc + '-'+ str(page) + '.html'\n",
    "        self.urls = self.url+self.params_list\n",
    "            \n",
    "        r = requests.get(self.urls, headers =self.headers )\n",
    "        self.soup = BeautifulSoup(r.content, 'lxml')\n",
    "        self.soup_posting = self.soup.find_all(attrs={'class':'jobwrap '})\n",
    "        print(self.params_list)\n",
    "        print(r.url)\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_number(x, get_last = False):\n",
    "        x = re.findall(r'\\d+', x)\n",
    "        return int(x[-1])\n",
    "    \n",
    "    def total_jobs(self):\n",
    "        job_number = self.soup.find(attrs= {'class':'count pull-left'}).get_text().strip()\n",
    "        no_jobs = self._get_number(job_number, get_last = True)\n",
    "        print(\"Total jobs found {}.\".format(no_jobs))\n",
    "        self.pages = [i for i in range(0, no_jobs, 40)]\n",
    "        \n",
    "    def get_jobs(self):\n",
    "        for job in self.soup_posting:\n",
    "            self.detail['title'].append(job.find(attrs = {'class':'title_in'}).get_text().strip())\n",
    "            self.detail['id'].append(job.get('id'))\n",
    "            self.detail['job_url'].append(job.find(attrs = {'class':'title_in'}).get('href'))\n",
    "            self.detail['company'].append(job.find(attrs = {'itemprop':'hiringOrganization'}).get_text().strip())\n",
    "            try:\n",
    "                self.detail['skills'].append(job.find(attrs = {'itemprop':'skills'}).get_text().strip())\n",
    "            except:\n",
    "                self.detail['skills'].append(None)\n",
    "                \n",
    "            try:\n",
    "                self.detail['location'].append(job.find(attrs = {'itemprop':'jobLocation'}).get_text().strip())\n",
    "            except:\n",
    "                self.detail['location'].append(None)\n",
    "                \n",
    "            try:\n",
    "                self.detail['experience'].append(job.find(attrs = {'itemprop':'experienceRequirements'}).get_text().strip())\n",
    "            except:\n",
    "                self.detail['experience'].append(None)\n",
    "                \n",
    "            try:\n",
    "                self.detail['date'].append(job.find(attrs = {'itemprop':'datePosted'}).get_text().strip())\n",
    "            except:\n",
    "                self.detail['date'].append(None)\n",
    "                \n",
    "            self.detail['query'].append(self.params_list)\n",
    "            \n",
    "    def get_all_jobs(self, q = '', loc = '', page=1):\n",
    "        \"\"\"Get all jobs\n",
    "        Params\n",
    "        -------\n",
    "        as_and: search query can be company number or title or any word in description\n",
    "        as_ttl: search only if present in title\n",
    "        as_cmp: company name\n",
    "        salary: Rs90000 will search Rs90000+ or Rs40K-Rs50K\n",
    "        l: location\n",
    "        start: start of search label detail\n",
    "        limit: no of job posting to display\n",
    "        kwargs: https://www.indeed.co.in/advanced_search\n",
    "            as_and=&as_phr=&as_any=&as_not=&as_ttl=&as_cmp=&\n",
    "            jt=all&st=&salary=&radius=25&l=&fromage=any&\n",
    "            limit=10&sort=&psf=advsrch\"\"\"\n",
    "        \n",
    "        #get number of pages in result\n",
    "        self.get_soups(q = q, loc = loc, page=page)\n",
    "        try:\n",
    "            self.total_jobs()\n",
    "            time.sleep(30)\n",
    "            for i,j in enumerate(self.pages):\n",
    "                print(\"Started scraping...\")\n",
    "                if i == 7:\n",
    "                    continue\n",
    "                self.get_soups(q = q, loc = loc, page=i+1)\n",
    "                self.get_jobs()\n",
    "        except:\n",
    "            print('No jobs..\\nTrying next item in list if any..\\n '.format(self.params_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Posted : 2nd Aug 2017'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.soup_posting[1].find(attrs = {'itemprop':'datePosted'}).get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-jobs-in-bengaluru-bangalore-1.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-1.html\n",
      "Total jobs found 1602.\n",
      "data-jobs-in-bengaluru-bangalore-1.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-1.html\n",
      "data-jobs-in-bengaluru-bangalore-2.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-2.html\n",
      "data-jobs-in-bengaluru-bangalore-3.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-3.html\n",
      "data-jobs-in-bengaluru-bangalore-4.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-4.html\n",
      "data-jobs-in-bengaluru-bangalore-5.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-5.html\n",
      "data-jobs-in-bengaluru-bangalore-6.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-6.html\n",
      "data-jobs-in-bengaluru-bangalore-7.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-7.html\n",
      "data-jobs-in-bengaluru-bangalore-8.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-8.html\n",
      "data-jobs-in-bengaluru-bangalore-9.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-9.html\n",
      "data-jobs-in-bengaluru-bangalore-10.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-10.html\n",
      "data-jobs-in-bengaluru-bangalore-11.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-11.html\n",
      "data-jobs-in-bengaluru-bangalore-12.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-12.html\n",
      "data-jobs-in-bengaluru-bangalore-13.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-13.html\n",
      "data-jobs-in-bengaluru-bangalore-14.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-14.html\n",
      "data-jobs-in-bengaluru-bangalore-15.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-15.html\n",
      "data-jobs-in-bengaluru-bangalore-16.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-16.html\n",
      "data-jobs-in-bengaluru-bangalore-17.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-17.html\n",
      "data-jobs-in-bengaluru-bangalore-18.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-18.html\n",
      "data-jobs-in-bengaluru-bangalore-19.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-19.html\n",
      "data-jobs-in-bengaluru-bangalore-20.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-20.html\n",
      "data-jobs-in-bengaluru-bangalore-21.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-21.html\n",
      "data-jobs-in-bengaluru-bangalore-22.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-22.html\n",
      "data-jobs-in-bengaluru-bangalore-23.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-23.html\n",
      "data-jobs-in-bengaluru-bangalore-24.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-24.html\n",
      "data-jobs-in-bengaluru-bangalore-25.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-25.html\n",
      "data-jobs-in-bengaluru-bangalore-26.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-26.html\n",
      "data-jobs-in-bengaluru-bangalore-27.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-27.html\n",
      "data-jobs-in-bengaluru-bangalore-28.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-28.html\n",
      "data-jobs-in-bengaluru-bangalore-29.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-29.html\n",
      "data-jobs-in-bengaluru-bangalore-30.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-30.html\n",
      "data-jobs-in-bengaluru-bangalore-31.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-31.html\n",
      "data-jobs-in-bengaluru-bangalore-32.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-32.html\n",
      "data-jobs-in-bengaluru-bangalore-33.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-33.html\n",
      "data-jobs-in-bengaluru-bangalore-34.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-34.html\n",
      "data-jobs-in-bengaluru-bangalore-35.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-35.html\n",
      "data-jobs-in-bengaluru-bangalore-36.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-36.html\n",
      "data-jobs-in-bengaluru-bangalore-37.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-37.html\n",
      "data-jobs-in-bengaluru-bangalore-38.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-38.html\n",
      "data-jobs-in-bengaluru-bangalore-39.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-39.html\n",
      "data-jobs-in-bengaluru-bangalore-40.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-40.html\n",
      "data-jobs-in-bengaluru-bangalore-41.html\n",
      "http://www.monsterindia.com/data-jobs-in-bengaluru-bangalore-41.html\n"
     ]
    }
   ],
   "source": [
    "def get_all_jobs(q='data', loc='bengaluru-bangalore'):\n",
    "    test =jobListing()\n",
    "    test.get_soups(q = q, loc = loc, page=1)\n",
    "    test.total_jobs()\n",
    "\n",
    "    for i, _ in enumerate(test.pages):\n",
    "        test.get_soups(q = q, loc = loc, page=i+1)\n",
    "        test.get_jobs()\n",
    "    \n",
    "    return test.detail\n",
    "\n",
    "all_jobs = get_all_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title >>> 1059\n",
      "id >>> 1262\n",
      "job_url >>> 1264\n",
      "company >>> 436\n",
      "skills >>> 973\n",
      "location >>> 34\n",
      "experience >>> 137\n",
      "date >>> 91\n",
      "query >>> 38\n"
     ]
    }
   ],
   "source": [
    "all_jobs.keys()\n",
    "\n",
    "for i in all_jobs.keys():\n",
    "    print(i,'>>>', len(set(all_jobs[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture output\n",
    "jobs_india =joblisting()\n",
    "for i in set(connections['Company']):\n",
    "    jobs_india.get_all_jobs(as_cmp=i)\n",
    "df = pd.DataFrame(jobs_india.detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(jobs_india.detail)\n",
    "df.drop_duplicates('id', inplace=True)\n",
    "df.to_excel(name_file+'.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2569c44faf66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
